{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Case 2 with Kaggle\nNeural Networks for Machine Learning Applications<br>\n26.2.2022, Xincheng Ni<br>\n[Information Technology](https://metropolia.fi/en/academics/bachelors-degrees/information-technology)<br>\n[Metropolia University of Applied Sciences](https://metropolia.fi/en)\n\nThe basic structure of this solution is taken from Tensorflow > Learn > Tensorflow Core > Tutorials > [Image Classification](https://www.tensorflow.org/tutorials/images/classification). See that for more detailed instructions.","metadata":{}},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"Pneumonia is an infection that inflames the air sacs in one or both lungs. The air sacs may fill with fluid or pus (purulent material), causing cough with phlegm or pus, fever, chills, and difficulty breathing. A variety of organisms, including bacteria, viruses and fungi, can cause pneumonia.\n\nIn this case, a dataset of [Chest X-Ray Images](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) are studied using  Convolutional Neural Network, to classify pneumonia X-Ray images. A simple `CNN model`, `VGG16` based model and `ResNet152V2` based model are used for practicing coding skill and find the best accuracy.\n\nThe dadaset consists of 5216 training samples and 624 tesing samples, labeled as \"NORMAL\" and \"PNEUMONIA\" in the subdirectory.\n\nNOTE: The result can still be improved, need more experiment and tuning, see 'Conclusion' part.","metadata":{}},{"cell_type":"markdown","source":"# Setup\n","metadata":{}},{"cell_type":"code","source":"%pylab inline\nimport os\nimport numpy as np \nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(\"tensorflow\", tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-03T17:49:29.09493Z","iopub.execute_input":"2022-04-03T17:49:29.095361Z","iopub.status.idle":"2022-04-03T17:49:34.986009Z","shell.execute_reply.started":"2022-04-03T17:49:29.095264Z","shell.execute_reply":"2022-04-03T17:49:34.98458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# Import dataset\ntrain_dir = '../input/chest-xray-pneumonia/chest_xray/train'\ntest_dir = '../input/chest-xray-pneumonia/chest_xray/test'\nval_dir = '../input/chest-xray-pneumonia/chest_xray/val'\n\n# Count normal and pneumonia samples for each dataset\nnum_train_normal = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\nnum_train_pneumonia = len(os.listdir(os.path.join(train_dir, 'PNEUMONIA')))\nprint(\"Train set:\")\nprint(f\"Normal:    {num_train_normal}\")\nprint(f\"Pneumonia: {num_train_pneumonia}\")\n\nnum_test_normal = len(os.listdir(os.path.join(test_dir, 'NORMAL')))\nnum_test_pneumonia = len(os.listdir(os.path.join(test_dir, 'PNEUMONIA')))\nprint(\"\\nTest set:\")\nprint(f\"Normal:    {num_test_normal}\")\nprint(f\"Pneumonia: {num_test_pneumonia}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:34.988426Z","iopub.execute_input":"2022-04-03T17:49:34.988919Z","iopub.status.idle":"2022-04-03T17:49:35.590703Z","shell.execute_reply.started":"2022-04-03T17:49:34.988875Z","shell.execute_reply":"2022-04-03T17:49:35.589564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize X-Ray images","metadata":{}},{"cell_type":"code","source":"normal_dir = os.path.join(train_dir, 'NORMAL')\nnormal = os.listdir(normal_dir)\n\nplt.figure(figsize=(10, 10))\nfor i in range(3):\n    plt.subplot(1, 3, i + 1)\n    img = plt.imread(os.path.join(normal_dir, normal[i]))\n    plt.imshow(img)\n    plt.title('Normal')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:35.592292Z","iopub.execute_input":"2022-04-03T17:49:35.592733Z","iopub.status.idle":"2022-04-03T17:49:36.361367Z","shell.execute_reply.started":"2022-04-03T17:49:35.592691Z","shell.execute_reply":"2022-04-03T17:49:36.360067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pneumonia_dir = os.path.join(train_dir, 'PNEUMONIA')\npneumonia = os.listdir(pneumonia_dir)\n\nplt.figure(figsize=(10, 10))\nfor i in range(3):\n    plt.subplot(1, 3, i + 1)\n    img = plt.imread(os.path.join(pneumonia_dir, pneumonia[i]))\n    plt.imshow(img)\n    plt.title('Pneumonia')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:36.362618Z","iopub.execute_input":"2022-04-03T17:49:36.362982Z","iopub.status.idle":"2022-04-03T17:49:37.022281Z","shell.execute_reply.started":"2022-04-03T17:49:36.362944Z","shell.execute_reply":"2022-04-03T17:49:37.021202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note the images above has various resolution. The difference between normal and pneumonia infection images is very difficult to tell for non-specialist.","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# This block is for raising brightness and contrast for future experiment\nimg_01 = '../input/chest-xray-pneumonia/chest_xray/test/NORMAL/IM-0001-0001.jpeg'\nimggg = plt.imread(img_01)\n\nimggg_3d = tf.expand_dims(imggg,2)\n\nbrighten = tf.image.adjust_brightness(imggg_3d, delta=0.2)\ncontrasten = tf.image.adjust_contrast(imggg_3d, 2.)\nprint(imggg.shape, imggg_3d.shape)\n\nplt.imshow(imggg)\nplt.title(\"Original img\")\nplt.show()\n\nplt.imshow(brighten)\nplt.title(\"Brightened img\")\nplt.show()\n\nplt.imshow(contrasten)\nplt.title(\"Contranst enhanced img\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:37.026911Z","iopub.execute_input":"2022-04-03T17:49:37.027563Z","iopub.status.idle":"2022-04-03T17:49:40.827514Z","shell.execute_reply.started":"2022-04-03T17:49:37.02752Z","shell.execute_reply":"2022-04-03T17:49:40.826243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Constant settings.","metadata":{}},{"cell_type":"code","source":"# Training settings\nBATCH_SIZE = 32\nIMG_HEIGHT, IMG_WIDTH = 240, 240\nIMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n\nN = 10           # epoch\nSTEPS_PER_EPOCH = 4173 / BATCH_SIZE\nVALIDATION_STEPS = 1043 / BATCH_SIZE\nMETRICS = ['accuracy']","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:40.831758Z","iopub.execute_input":"2022-04-03T17:49:40.832474Z","iopub.status.idle":"2022-04-03T17:49:40.839975Z","shell.execute_reply.started":"2022-04-03T17:49:40.832431Z","shell.execute_reply":"2022-04-03T17:49:40.838834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use `ImageDataGenerator` for preprocessing and augmenting data.\n\nrescale:             Rescale pixel value into 0-1.<br>\nrotation_range:      Rotate image for random degree range.<br>\nwidth_shift_range:   Shift image horizontally.<br>\nheight_shift_range:  Shift image vertically.<br>\nshear_range:         Shear angle in counter-clockwise direction in degrees.<br>\nzoom_range:          Zoom for random range.","metadata":{}},{"cell_type":"code","source":"def custom_augmentation(np_tensor):\n \n    def random_contrast(np_tensor):\n        return tf.image.random_contrast(np_tensor, 0.5, 2)\n\n    augmnted_tensor = random_contrast(np_tensor)\n    return np.array(augmnted_tensor)\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   rotation_range = 20,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   brightness_range = (1, 1.2),\n                                   preprocessing_function=custom_augmentation,\n                                   validation_split = 0.2)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:40.842017Z","iopub.execute_input":"2022-04-03T17:49:40.842534Z","iopub.status.idle":"2022-04-03T17:49:40.853305Z","shell.execute_reply.started":"2022-04-03T17:49:40.842474Z","shell.execute_reply":"2022-04-03T17:49:40.851967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Iterate through dataset directories and prepare data.","metadata":{}},{"cell_type":"code","source":"train_ds = train_datagen.flow_from_directory(train_dir,\n                                             subset = \"training\",\n                                             class_mode = 'binary',\n#                                              shuffle = True,\n                                             seed = 123,\n                                             target_size = IMG_SIZE,\n                                             batch_size = BATCH_SIZE)\n\nval_ds = train_datagen.flow_from_directory(train_dir,\n                                           subset = \"validation\",\n                                           class_mode = 'binary',\n                                           shuffle = False,\n                                           seed = 123,\n                                           target_size = IMG_SIZE,\n                                           batch_size = BATCH_SIZE)\n\ntest_ds = test_datagen.flow_from_directory(test_dir,\n                                           class_mode = 'binary',\n                                           shuffle = False,\n                                           target_size = IMG_SIZE,\n                                           batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:40.855372Z","iopub.execute_input":"2022-04-03T17:49:40.855902Z","iopub.status.idle":"2022-04-03T17:49:45.458068Z","shell.execute_reply.started":"2022-04-03T17:49:40.855854Z","shell.execute_reply":"2022-04-03T17:49:45.45659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Speed up","metadata":{}},{"cell_type":"code","source":"# # Speeding up the data processing\n# AUTOTUNE = tf.data.experimental.AUTOTUNE\n# train_datagen = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:45.45947Z","iopub.execute_input":"2022-04-03T17:49:45.459837Z","iopub.status.idle":"2022-04-03T17:49:45.464276Z","shell.execute_reply.started":"2022-04-03T17:49:45.459809Z","shell.execute_reply":"2022-04-03T17:49:45.462938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1 - Simple CNN model","metadata":{}},{"cell_type":"markdown","source":"### Modeling","metadata":{}},{"cell_type":"markdown","source":"Building a simple CNN model. Apply dropout after flatten layer.","metadata":{}},{"cell_type":"code","source":"cls_wt = class_weight.compute_class_weight('balanced',\n                                           np.unique(train_ds.classes),\n                                           train_ds.classes)\nclass_weights = {0: cls_wt[0], 1:cls_wt[1]}\nprint(class_weights)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:45.466078Z","iopub.execute_input":"2022-04-03T17:49:45.46678Z","iopub.status.idle":"2022-04-03T17:49:45.486307Z","shell.execute_reply.started":"2022-04-03T17:49:45.466739Z","shell.execute_reply":"2022-04-03T17:49:45.484171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1 = Sequential([\n#     layers.experimental.preprocessing.RandomContrast(factor=0.2, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n\n    layers.Conv2D(64, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n    layers.BatchNormalization(),\n#     layers.Conv2D(32, 3, padding='same', activation='relu'),\n#     layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n    \n#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n#     layers.BatchNormalization(),\n    layers.Conv2D(128, 3, padding='same', activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n    \n#     layers.Conv2D(128, 3, padding='same', activation='relu'),\n#     layers.BatchNormalization(),\n    layers.Conv2D(256, 3, padding='same', activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n    \n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.2),\n\n    layers.Dense(1, activation = 'sigmoid')\n])\n\nmodel_1.compile(optimizer = optimizers.RMSprop(learning_rate = 1e-4),\n                loss = 'binary_crossentropy',\n                metrics = METRICS)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:45.4876Z","iopub.execute_input":"2022-04-03T17:49:45.488017Z","iopub.status.idle":"2022-04-03T17:49:45.810508Z","shell.execute_reply.started":"2022-04-03T17:49:45.487979Z","shell.execute_reply":"2022-04-03T17:49:45.809612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:45.812011Z","iopub.execute_input":"2022-04-03T17:49:45.812398Z","iopub.status.idle":"2022-04-03T17:49:45.829302Z","shell.execute_reply.started":"2022-04-03T17:49:45.812345Z","shell.execute_reply":"2022-04-03T17:49:45.828419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create checkpoint callback to save best result.","metadata":{}},{"cell_type":"code","source":"checkpoint_filepath = \"model_1_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n\ncheckpoint_model_1 = ModelCheckpoint(filepath=os.path.join(\"./case2/checkpoint\", checkpoint_filepath), \n                                     monitor='val_accuracy',\n                                     verbose=0, \n                                     save_best_only=True)\ncallbacks_1 = [checkpoint_model_1]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:45.8335Z","iopub.execute_input":"2022-04-03T17:49:45.833775Z","iopub.status.idle":"2022-04-03T17:49:45.839494Z","shell.execute_reply.started":"2022-04-03T17:49:45.833749Z","shell.execute_reply":"2022-04-03T17:49:45.838125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"%%time\n\nh1 = model_1.fit(train_ds,\n                validation_data = val_ds,\n                batch_size = BATCH_SIZE,\n                steps_per_epoch = STEPS_PER_EPOCH,\n                validation_steps = VALIDATION_STEPS,\n                 class_weight = class_weights,\n                verbose = 1, # FOR FINAL VERSION, CHANGE TO 0!\n                epochs = N,\n                callbacks = checkpoint_model_1)\n\nmodel_filepath = os.path.join(\"./case2/model\", \"model_1.h5\")\nmodel_1.save(model_filepath)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T17:49:45.840946Z","iopub.execute_input":"2022-04-03T17:49:45.841457Z","iopub.status.idle":"2022-04-03T18:16:16.273714Z","shell.execute_reply.started":"2022-04-03T17:49:45.84136Z","shell.execute_reply":"2022-04-03T18:16:16.272627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean Loss:         {np.array(h1.history['loss']).mean()}\")\nprint(f\"Mean Accuracy:     {np.array(h1.history['accuracy']).mean()}\")\nprint(f\"Mean Val-Loss:     {np.array(h1.history['val_loss']).mean()}\")\nprint(f\"Mean Val-Accuracy: {np.array(h1.history['val_accuracy']).mean()}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:16:16.275536Z","iopub.execute_input":"2022-04-03T18:16:16.276001Z","iopub.status.idle":"2022-04-03T18:16:16.285092Z","shell.execute_reply.started":"2022-04-03T18:16:16.275941Z","shell.execute_reply":"2022-04-03T18:16:16.283645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot graphs for training history.","metadata":{}},{"cell_type":"code","source":"x = range(1, N+1)\n\nfigure(figsize(13, 5))\nsubplot(1, 2, 1)\nplot(x, h1.history['loss'], '*-', label = 'training')\nplot(x, h1.history['val_loss'], 'o-', label = 'validation')\ntitle('loss')\nylim(0, )\nlegend()\ngrid()\n\nsubplot(1, 2, 2)\nplot(x, h1.history['accuracy'], '*-', label = 'training')\nplot(x, h1.history['val_accuracy'], 'o-', label = 'validation')\ntitle('accuracy')\nylim(0.5, 1.0)\nlegend()\ngrid()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:16:16.286926Z","iopub.execute_input":"2022-04-03T18:16:16.287422Z","iopub.status.idle":"2022-04-03T18:16:16.661417Z","shell.execute_reply.started":"2022-04-03T18:16:16.287379Z","shell.execute_reply":"2022-04-03T18:16:16.660236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Result","metadata":{}},{"cell_type":"code","source":"model_1.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:16:16.663246Z","iopub.execute_input":"2022-04-03T18:16:16.664112Z","iopub.status.idle":"2022-04-03T18:16:28.869235Z","shell.execute_reply.started":"2022-04-03T18:16:16.664068Z","shell.execute_reply":"2022-04-03T18:16:28.868235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1_pred = (model_1.predict(test_ds) > 0.5).astype(\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:16:28.871798Z","iopub.execute_input":"2022-04-03T18:16:28.87223Z","iopub.status.idle":"2022-04-03T18:16:36.090364Z","shell.execute_reply.started":"2022-04-03T18:16:28.872188Z","shell.execute_reply":"2022-04-03T18:16:36.089358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(test_ds.classes, m1_pred)\n\nsen = cm[0][0] / ((cm[0][0]) + (cm[0][1]))\nspe = cm[1][1] / ((cm[1][0]) + (cm[1][1]))\n\nprint(cm)\nprint(f\"Sensitivity: {sen}\")\nprint(f\"Specificity: {spe}\")\nprint(classification_report(test_ds.classes, m1_pred, target_names=['Normal - 0', 'Pneumonia - 1']))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:16:36.092926Z","iopub.execute_input":"2022-04-03T18:16:36.093659Z","iopub.status.idle":"2022-04-03T18:16:36.11565Z","shell.execute_reply.started":"2022-04-03T18:16:36.093612Z","shell.execute_reply":"2022-04-03T18:16:36.114326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2 - VGG16","metadata":{}},{"cell_type":"markdown","source":"### Modeling","metadata":{}},{"cell_type":"markdown","source":"Building a VGG16 based model.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\n\nvgg16_base = VGG16(weights='imagenet', include_top=False,\n                  input_shape=(IMG_HEIGHT, IMG_WIDTH,3), pooling='avg')\nvgg16_base.trainable = False\n\n# vgg16_base.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:16:36.117311Z","iopub.execute_input":"2022-04-03T18:16:36.118238Z","iopub.status.idle":"2022-04-03T18:16:38.624787Z","shell.execute_reply.started":"2022-04-03T18:16:36.118197Z","shell.execute_reply":"2022-04-03T18:16:38.623792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_model = tf.keras.Sequential([vgg16_base,\n                                   layers.Dense(128, activation=\"relu\"),\n                                   layers.Dropout(0.2),\n                                   layers.BatchNormalization(),\n                                   layers.Dense(64,activation=\"relu\"),\n                                   layers.Dropout(0.2),\n                                   layers.BatchNormalization(),\n                                   layers.Dense(1,activation=\"sigmoid\")])\n\nvgg16_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n                    loss='binary_crossentropy',\n                    metrics=METRICS)\n\nvgg16_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:16:38.626431Z","iopub.execute_input":"2022-04-03T18:16:38.626867Z","iopub.status.idle":"2022-04-03T18:16:38.778903Z","shell.execute_reply.started":"2022-04-03T18:16:38.626799Z","shell.execute_reply":"2022-04-03T18:16:38.777873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = \"vgg16_model_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n\ncheckpoint_model_vgg16 = ModelCheckpoint(filepath=os.path.join(\"./case2/checkpoint\", checkpoint_filepath), \n                                     monitor='val_accuracy',\n                                     verbose=0, \n                                     save_best_only=True)\ncallbacks_2 = [checkpoint_model_vgg16]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:16:38.782898Z","iopub.execute_input":"2022-04-03T18:16:38.78321Z","iopub.status.idle":"2022-04-03T18:16:38.789723Z","shell.execute_reply.started":"2022-04-03T18:16:38.783179Z","shell.execute_reply":"2022-04-03T18:16:38.788239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"%%time\n\nh2 = vgg16_model.fit(train_ds,\n                     validation_data = val_ds,\n                     batch_size = BATCH_SIZE,\n                     steps_per_epoch = STEPS_PER_EPOCH,\n                     validation_steps = VALIDATION_STEPS,\n                     verbose = 1, # FOR FINAL VERSION, CHANGE TO 0!\n                     epochs = N,\n                     callbacks = callbacks_2)\n\nmodel_filepath = os.path.join(\"./case2/model\", \"vgg16_model.h5\")\nvgg16_model.save(model_filepath)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:16:38.791981Z","iopub.execute_input":"2022-04-03T18:16:38.792456Z","iopub.status.idle":"2022-04-03T18:41:22.759299Z","shell.execute_reply.started":"2022-04-03T18:16:38.792404Z","shell.execute_reply":"2022-04-03T18:41:22.758023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean Loss:         {np.array(h2.history['loss']).mean()}\")\nprint(f\"Mean Accuracy:     {np.array(h2.history['accuracy']).mean()}\")\nprint(f\"Mean Val-Loss:     {np.array(h2.history['val_loss']).mean()}\")\nprint(f\"Mean Val-Accuracy: {np.array(h2.history['val_accuracy']).mean()}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:41:22.762833Z","iopub.execute_input":"2022-04-03T18:41:22.763153Z","iopub.status.idle":"2022-04-03T18:41:22.773652Z","shell.execute_reply.started":"2022-04-03T18:41:22.763121Z","shell.execute_reply":"2022-04-03T18:41:22.772011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure(figsize(13, 5))\nsubplot(1, 2, 1)\nplot(x, h2.history['loss'], '*-', label = 'training')\nplot(x, h2.history['val_loss'], 'o-', label = 'validation')\ntitle('loss')\nylim(0, )\nlegend()\ngrid()\n\nsubplot(1, 2, 2)\nplot(x, h2.history['accuracy'], '*-', label = 'training')\nplot(x, h2.history['val_accuracy'], 'o-', label = 'validation')\ntitle('accuracy')\nylim(0.5, 1.0)\nlegend()\ngrid()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:41:22.775144Z","iopub.execute_input":"2022-04-03T18:41:22.775612Z","iopub.status.idle":"2022-04-03T18:41:23.123613Z","shell.execute_reply.started":"2022-04-03T18:41:22.775569Z","shell.execute_reply":"2022-04-03T18:41:23.122311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Result","metadata":{}},{"cell_type":"code","source":"vgg16_model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:41:23.127311Z","iopub.execute_input":"2022-04-03T18:41:23.127703Z","iopub.status.idle":"2022-04-03T18:41:31.184788Z","shell.execute_reply.started":"2022-04-03T18:41:23.127671Z","shell.execute_reply":"2022-04-03T18:41:31.183917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m2_pred = (vgg16_model.predict(test_ds) > 0.5).astype(\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:41:31.186409Z","iopub.execute_input":"2022-04-03T18:41:31.186804Z","iopub.status.idle":"2022-04-03T18:41:38.242289Z","shell.execute_reply.started":"2022-04-03T18:41:31.186775Z","shell.execute_reply":"2022-04-03T18:41:38.240917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(test_ds.classes, m2_pred)\nsen = cm[0][0] / ((cm[0][0]) + (cm[0][1]))\nspe = cm[1][1] / ((cm[1][0]) + (cm[1][1]))\n\nprint(cm)\nprint(f\"Sensitivity: {sen}\")\nprint(f\"Specificity: {spe}\")\nprint(classification_report(test_ds.classes, m2_pred, target_names=['Normal - 0', 'Pneumonia - 1']))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:41:38.244263Z","iopub.execute_input":"2022-04-03T18:41:38.244784Z","iopub.status.idle":"2022-04-03T18:41:38.267722Z","shell.execute_reply.started":"2022-04-03T18:41:38.244739Z","shell.execute_reply":"2022-04-03T18:41:38.265939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 3 - EfficientNetB5","metadata":{}},{"cell_type":"markdown","source":"### Modeling","metadata":{}},{"cell_type":"markdown","source":"Building a EfficientNetB5 based model.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n\nResNet152V2_base = ResNet152V2(weights='imagenet', include_top=False,\n                  input_shape=(IMG_HEIGHT, IMG_WIDTH,3), pooling='avg')\nResNet152V2_base.trainable = False\n\n# ResNet152V2_base.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:41:38.269461Z","iopub.execute_input":"2022-04-03T18:41:38.269926Z","iopub.status.idle":"2022-04-03T18:41:45.769406Z","shell.execute_reply.started":"2022-04-03T18:41:38.269883Z","shell.execute_reply":"2022-04-03T18:41:45.768401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResNet152V2_model = tf.keras.Sequential([ResNet152V2_base,\n                                         layers.Dense(128,activation=\"relu\"),\n                                         layers.Dropout(0.2),\n                                         layers.BatchNormalization(),\n                                         layers.Dense(1,activation=\"sigmoid\")])\n\nResNet152V2_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n                    loss='binary_crossentropy',\n                    metrics=METRICS)\n\nResNet152V2_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:41:45.770941Z","iopub.execute_input":"2022-04-03T18:41:45.771336Z","iopub.status.idle":"2022-04-03T18:41:47.141963Z","shell.execute_reply.started":"2022-04-03T18:41:45.771295Z","shell.execute_reply":"2022-04-03T18:41:47.141065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = \"ResNet152V2_model_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n\ncheckpoint_model_ResNet152V2 = ModelCheckpoint(filepath=os.path.join(\"./case2/checkpoint\", checkpoint_filepath), \n                                     monitor='val_accuracy',\n                                     verbose=0, \n                                     save_best_only=True)\ncallbacks_3 = [checkpoint_model_ResNet152V2]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:41:47.144853Z","iopub.execute_input":"2022-04-03T18:41:47.145305Z","iopub.status.idle":"2022-04-03T18:41:47.15111Z","shell.execute_reply.started":"2022-04-03T18:41:47.145266Z","shell.execute_reply":"2022-04-03T18:41:47.149681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"%%time\n\nh3 = ResNet152V2_model.fit(train_ds,\n                        validation_data = val_ds,\n                        batch_size = BATCH_SIZE,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        validation_steps = VALIDATION_STEPS,\n                        verbose = 1, # FOR FINAL VERSION, CHANGE TO 0!\n                        epochs = N,\n                        callbacks = callbacks_3)\n\nmodel_filepath = os.path.join(\"./case2/model\", \"ResNet152V2_model.h5\")\nResNet152V2_model.save(model_filepath)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T18:41:47.158106Z","iopub.execute_input":"2022-04-03T18:41:47.158575Z","iopub.status.idle":"2022-04-03T19:08:55.027145Z","shell.execute_reply.started":"2022-04-03T18:41:47.158527Z","shell.execute_reply":"2022-04-03T19:08:55.02485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean Loss:         {np.array(h3.history['loss']).mean()}\")\nprint(f\"Mean Accuracy:     {np.array(h3.history['accuracy']).mean()}\")\nprint(f\"Mean Val-Loss:     {np.array(h3.history['val_loss']).mean()}\")\nprint(f\"Mean Val-Accuracy: {np.array(h3.history['val_accuracy']).mean()}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T19:08:55.029446Z","iopub.execute_input":"2022-04-03T19:08:55.029894Z","iopub.status.idle":"2022-04-03T19:08:55.041711Z","shell.execute_reply.started":"2022-04-03T19:08:55.029847Z","shell.execute_reply":"2022-04-03T19:08:55.036067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure(figsize(13, 5))\nsubplot(1, 2, 1)\nplot(x, h3.history['loss'], '*-', label = 'training')\nplot(x, h3.history['val_loss'], 'o-', label = 'validation')\ntitle('loss')\nylim(0, )\nlegend()\ngrid()\n\nsubplot(1, 2, 2)\nplot(x, h3.history['accuracy'], '*-', label = 'training')\nplot(x, h3.history['val_accuracy'], 'o-', label = 'validation')\ntitle('accuracy')\nylim(0.5, 1.0)\nlegend()\ngrid()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T19:08:55.043881Z","iopub.execute_input":"2022-04-03T19:08:55.044304Z","iopub.status.idle":"2022-04-03T19:08:55.420024Z","shell.execute_reply.started":"2022-04-03T19:08:55.044262Z","shell.execute_reply":"2022-04-03T19:08:55.418849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Result","metadata":{}},{"cell_type":"code","source":"ResNet152V2_model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T19:08:55.421728Z","iopub.execute_input":"2022-04-03T19:08:55.422447Z","iopub.status.idle":"2022-04-03T19:09:04.013039Z","shell.execute_reply.started":"2022-04-03T19:08:55.422398Z","shell.execute_reply":"2022-04-03T19:09:04.011906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m3_pred = (ResNet152V2_model.predict(test_ds) > 0.5).astype(\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T19:09:04.014731Z","iopub.execute_input":"2022-04-03T19:09:04.015386Z","iopub.status.idle":"2022-04-03T19:09:14.0065Z","shell.execute_reply.started":"2022-04-03T19:09:04.015325Z","shell.execute_reply":"2022-04-03T19:09:14.005469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(test_ds.classes, m3_pred)\nsen = cm[0][0] / ((cm[0][0]) + (cm[0][1]))\nspe = cm[1][1] / ((cm[1][0]) + (cm[1][1]))\n\nprint(cm)\nprint(f\"Sensitivity: {sen}\")\nprint(f\"Specificity: {spe}\")\nprint(classification_report(test_ds.classes, m3_pred, target_names=['Normal - 0', 'Pneumonia - 1']))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T19:09:14.008093Z","iopub.execute_input":"2022-04-03T19:09:14.008505Z","iopub.status.idle":"2022-04-03T19:09:14.031226Z","shell.execute_reply.started":"2022-04-03T19:09:14.008462Z","shell.execute_reply":"2022-04-03T19:09:14.030035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nFor further improvement, I would try:\n1. Bigger image size e.g(300 * 300)\n2. Higher contrast or brightness\n3. Using grayscale\n4. Reduce layers/neurons to fight overfitting\n\nHelpful links:  \n[VGG16_grayscale](https://github.com/DaveRichmond-/grayscale-imagenet/tree/master/models)  \n[imagenet_grayscale](https://github.com/DaveRichmond-/grayscale-imagenet)","metadata":{}}]}